{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN2v9afeOsLEQc54nGkkkt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Osondu-ifunanya/Surface-water-mapping-using-ML-on-NDWI-enhanced-imagery/blob/main/SurfaceWaterMapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWHOfgYK67j8"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from skimage.util import random_noise\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Generate synthetic imagery\n",
        "# -----------------------------\n",
        "np.random.seed(42)\n",
        "\n",
        "n_images = 500            # number of image patches (samples)\n",
        "img_h, img_w = 32, 32     # patch size\n",
        "bands = ['Green', 'NIR']  # we simulate two bands to compute NDWI\n",
        "\n",
        "# Helper to create synthetic patch\n",
        "def make_patch(is_water, h=img_h, w=img_w):\n",
        "    \"\"\"\n",
        "    Create a synthetic patch:\n",
        "      - water: low Green, high NIR? (for NDWI we often use (Green - NIR)/(Green + NIR))\n",
        "      - non-water: higher Green relative to NIR or textured\n",
        "    We'll simulate realistic contrasts and add noise.\n",
        "    \"\"\"\n",
        "    if is_water:\n",
        "        # water: generally low reflectance in NIR, moderate in green\n",
        "        green = np.random.uniform(0.06, 0.25, size=(h, w))\n",
        "        nir   = np.random.uniform(0.02, 0.12, size=(h, w))\n",
        "        # add calm-water specular spots\n",
        "        mask_spots = (np.random.rand(h, w) > 0.995)\n",
        "        green[mask_spots] += np.random.uniform(0.1, 0.3)\n",
        "    else:\n",
        "        # land: vegetation/soil -> higher NIR, variable green\n",
        "        green = np.random.uniform(0.05, 0.6, size=(h, w))\n",
        "        nir   = np.random.uniform(0.1, 0.8, size=(h, w))\n",
        "        # simulate textures: fields, built-up\n",
        "        if np.random.rand() < 0.5:\n",
        "            green += np.random.normal(0, 0.02, size=(h, w))\n",
        "            nir   += np.random.normal(0, 0.03, size=(h, w))\n",
        "\n",
        "    # clip and add small Gaussian noise\n",
        "    green = np.clip(random_noise(green, mode='gaussian', var=1e-4), 0, 1)\n",
        "    nir   = np.clip(random_noise(nir,   mode='gaussian', var=1e-4), 0, 1)\n",
        "    return green.astype(np.float32), nir.astype(np.float32)\n",
        "\n",
        "# Build dataset\n",
        "patches_green = []\n",
        "patches_nir = []\n",
        "labels = []\n",
        "\n",
        "for i in range(n_images):\n",
        "    # randomly assign water prevalence: allow some mixed patches\n",
        "    is_water = np.random.rand() < 0.4  # 40% water patches on average\n",
        "    g, n = make_patch(is_water)\n",
        "    # optionally create mixed patches (partial water)\n",
        "    if np.random.rand() < 0.2:\n",
        "        # mix with opposite class small region\n",
        "        g2, n2 = make_patch(not is_water)\n",
        "        # overlay a rectangle of g2 onto center\n",
        "        r_h, r_w = int(img_h*0.3), int(img_w*0.3)\n",
        "        y0 = (img_h - r_h)//2; x0 = (img_w - r_w)//2\n",
        "        g[y0:y0+r_h, x0:x0+r_w] = g2[y0:y0+r_h, x0:x0+r_w]\n",
        "        n[y0:y0+r_h, x0:x0+r_w] = n2[y0:y0+r_h, x0:x0+r_w]\n",
        "        # label as water if majority pixels are water according to simple NDWI rule\n",
        "        # we'll compute true label below\n",
        "    patches_green.append(g)\n",
        "    patches_nir.append(n)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Compute NDWI and derive labels\n",
        "# -----------------------------\n",
        "def compute_ndwi(g, n):\n",
        "    # NDWI = (Green - NIR) / (Green + NIR)\n",
        "    denom = (g + n)\n",
        "    # avoid division by zero\n",
        "    denom = np.where(denom == 0, 1e-6, denom)\n",
        "    return (g - n) / denom\n",
        "\n",
        "ndwi_patches = [compute_ndwi(g, n) for g, n in zip(patches_green, patches_nir)]\n",
        "\n",
        "# Derive binary label per patch: water if > threshold fraction of pixels have NDWI > 0\n",
        "ndwi_threshold = 0.0\n",
        "water_fraction_threshold = 0.3  # if 30%+ pixels indicate water -> patch = water\n",
        "\n",
        "for ndwi in ndwi_patches:\n",
        "    water_pixels = (ndwi > ndwi_threshold).sum()\n",
        "    frac = water_pixels / (img_h * img_w)\n",
        "    labels.append(1 if frac >= water_fraction_threshold else 0)\n",
        "\n",
        "# Build feature vectors: use NDWI statistics + spectral band stats (can be expanded)\n",
        "X_features = []\n",
        "for g, n, nd in zip(patches_green, patches_nir, ndwi_patches):\n",
        "    feat = [\n",
        "        nd.mean(),\n",
        "        nd.std(),\n",
        "        np.percentile(nd.flatten(), 75),\n",
        "        np.percentile(nd.flatten(), 25),\n",
        "        g.mean(),\n",
        "        g.std(),\n",
        "        n.mean(),\n",
        "        n.std(),\n",
        "    ]\n",
        "    X_features.append(feat)\n",
        "\n",
        "X = np.array(X_features)\n",
        "y = np.array(labels)\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Train/test split and model\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=200, random_state=42, min_samples_leaf=3)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Evaluation\n",
        "# -----------------------------\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Visualize some examples (NDWI map + predicted label)\n",
        "# -----------------------------\n",
        "def show_patch(idx):\n",
        "    g = patches_green[idx]\n",
        "    n = patches_nir[idx]\n",
        "    nd = compute_ndwi(g, n)\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
        "    axes[0].imshow(g, cmap='Greens'); axes[0].set_title('Green')\n",
        "    axes[1].imshow(n, cmap='inferno'); axes[1].set_title('NIR')\n",
        "    im = axes[2].imshow(nd, cmap='BrBG', vmin=-1, vmax=1)\n",
        "    axes[2].set_title(f'NDWI\\nTrue={y[idx]}')\n",
        "    fig.colorbar(im, ax=axes[2], fraction=0.046)\n",
        "    plt.suptitle(f\"Sample {idx} - Predicted (by model on patch stats): {clf.predict([X_features[idx]])[0]}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# show a few examples (some water, some non-water)\n",
        "for idx in [0, 5, 12]:\n",
        "    show_patch(idx)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Feature importance\n",
        "# -----------------------------\n",
        "feat_names = ['NDWI_mean','NDWI_std','NDWI_p75','NDWI_p25','G_mean','G_std','NIR_mean','NIR_std']\n",
        "importances = clf.feature_importances_\n",
        "fi_df = pd.DataFrame({'feature': feat_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
        "print(\"\\nFeature importances:\\n\", fi_df)\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Export dataset (per-patch) to Excel for inspection\n",
        "# -----------------------------\n",
        "df_export = pd.DataFrame(X, columns=feat_names)\n",
        "df_export['Label'] = y\n",
        "# add a few raw stats for context\n",
        "df_export['WaterPixelFraction'] = [(nd > ndwi_threshold).sum()/(img_h*img_w) for nd in ndwi_patches]\n",
        "excel_path = \"synthetic_surface_water_dataset.xlsx\"\n",
        "df_export.to_excel(excel_path, index=False)\n",
        "print(f\"\\nExported dataset to: {excel_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 8. Optional: Pixel-level classifier (demo)\n",
        "# Build a pixel-wise dataset (NDWI per pixel) to train a pixel classifier\n",
        "# -----------------------------\n",
        "# Create pixel-level features and labels (this demonstrates more granular mapping)\n",
        "pixel_feats = []\n",
        "pixel_labels = []\n",
        "for nd, g, n in zip(ndwi_patches, patches_green, patches_nir):\n",
        "    # Each pixel described by [NDWI, Green, NIR]\n",
        "    pix_feat = np.stack([nd.flatten(), g.flatten(), n.flatten()], axis=1)\n",
        "    # label pixel water if NDWI > threshold\n",
        "    pix_label = (nd.flatten() > ndwi_threshold).astype(int)\n",
        "    pixel_feats.append(pix_feat)\n",
        "    pixel_labels.append(pix_label)\n",
        "\n",
        "pixel_X = np.vstack(pixel_feats)\n",
        "pixel_y = np.hstack(pixel_labels)\n",
        "\n",
        "# sample down for speed\n",
        "sample_idx = np.random.choice(len(pixel_y), size=min(20000, len(pixel_y)), replace=False)\n",
        "pixel_X_s = pixel_X[sample_idx]\n",
        "pixel_y_s = pixel_y[sample_idx]\n",
        "\n",
        "px_X_train, px_X_test, px_y_train, px_y_test = train_test_split(pixel_X_s, pixel_y_s, test_size=0.3, random_state=42, stratify=pixel_y_s)\n",
        "px_clf = RandomForestClassifier(n_estimators=100, random_state=42, min_samples_leaf=5)\n",
        "px_clf.fit(px_X_train, px_y_train)\n",
        "px_pred = px_clf.predict(px_X_test)\n",
        "print(\"\\nPixel-level classifier accuracy:\", accuracy_score(px_y_test, px_pred))\n",
        "\n"
      ]
    }
  ]
}